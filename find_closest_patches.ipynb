{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import models.ae as ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = 'weights/'\n",
    "weights_path = os.path.join(weights_dir, 'ae_best.pth.tar')\n",
    "\n",
    "data_dir = 'images/'\n",
    "image_path = os.path.join(data_dir, 'data_0165.png')\n",
    "query_patch_path = os.path.join(data_dir, 'data_0165_mito_crop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imageio.imread(image_path)\n",
    "query_patch = imageio.imread(query_patch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE(\n",
       "  (zeropad1): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (zeropad2): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (zeropad3): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_enc): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (fc_dec): Linear(in_features=32, out_features=2048, bias=True)\n",
       "  (t_conv1): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (t_conv2): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (t_conv3): ConvTranspose2d(32, 1, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (loss): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ae.AE(32)\n",
    "model.load_state_dict(torch.load(weights_path)['state_dict'])\n",
    "model.eval()\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssd(img1, img2):\n",
    "    \"\"\"Computing the sum of squared differences (SSD) between two images.\"\"\"\n",
    "    if img1.shape != img2.shape:\n",
    "        raise Exception(\"Images don't have the same shape: \", img1.shape, \"and\", img2.shape)\n",
    "    return np.sum((np.array(img1, dtype=np.float32) - np.array(img2, dtype=np.float32))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptor(descr, patch):\n",
    "    variational = False  # isinstance(descr, vae.BetaVAE) or isinstance(descr, vae_ir.BetaVAE)\n",
    "    patch = np.array(patch)\n",
    "    patch = patch / 255.0\n",
    "    patch = np.expand_dims(np.expand_dims(patch, axis=0), axis=0)\n",
    "    patch = torch.from_numpy(patch).float()\n",
    "    if variational:\n",
    "        patch_encoding, _, _ = descr.encode(patch)\n",
    "    else:\n",
    "        patch_encoding = descr.encode(patch)\n",
    "    patch_encoding = patch_encoding.detach().numpy()\n",
    "    patch_encoding = patch_encoding.reshape(patch_encoding.shape[0], np.product(patch_encoding.shape[1:]))\n",
    "    return patch_encoding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 65\n",
    "compare_stride = 8\n",
    "eps = 0.0001\n",
    "nr_similar_patches = 6\n",
    "\n",
    "\n",
    "image_height = image.shape[0]\n",
    "image_width = image.shape[1]\n",
    "\n",
    "query_patch_descr = compute_descriptor(model, query_patch)\n",
    "\n",
    "counter_compare_patches = 0\n",
    "\n",
    "patches_diffs = [1000000000]\n",
    "patches_x_coords = [-1]\n",
    "patches_y_coords = [-1]\n",
    "patches_positions = [-1]\n",
    "\n",
    "\n",
    "for y_compare in range(0, image_width - patch_size + 1, compare_stride):\n",
    "    for x_compare in range(0, image_height - patch_size + 1, compare_stride):\n",
    "\n",
    "        compare_patch = image[x_compare: x_compare + patch_size, y_compare: y_compare + patch_size]\n",
    "\n",
    "        compare_patch_descr = compute_descriptor(model, compare_patch)\n",
    "\n",
    "        diff = calculate_ssd(query_patch_descr, compare_patch_descr)\n",
    "\n",
    "        if diff < eps:  # or (x_compare == x_query and y_compare == y_query):\n",
    "            counter_compare_patches += 1\n",
    "            continue\n",
    "\n",
    "        # sorting\n",
    "        for i in range(len(patches_diffs)):\n",
    "            if diff < patches_diffs[i]:\n",
    "                patches_diffs.insert(i, diff)\n",
    "                patches_x_coords.insert(i, x_compare)\n",
    "                patches_y_coords.insert(i, y_compare)\n",
    "                patches_positions.insert(i, counter_compare_patches)\n",
    "                break\n",
    "\n",
    "        counter_compare_patches += 1\n",
    "\n",
    "results_patches_diffs = patches_diffs[:nr_similar_patches]\n",
    "results_patches_x_coords = patches_x_coords[:nr_similar_patches]\n",
    "results_patches_y_coords = patches_y_coords[:nr_similar_patches]\n",
    "results_patches_positions = patches_positions[:nr_similar_patches]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image, cmap='gray')\n",
    "\n",
    "for i, patch_match in enumerate(results_patches_positions):\n",
    "    rect = patches.Rectangle((results_patches_x_coords[i], results_patches_y_coords[i]),\n",
    "                             65, 65, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
